{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**THEORY QUESTIONS**"
      ],
      "metadata": {
        "id": "D--NZe2ioZ1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Logistic Regression is a classification algorithm used to predict categorical outcomes (e.g., spam vs. not spam).\n",
        "\n",
        "Linear Regression is used for regression tasks, predicting continuous values.\n",
        "The key difference: Logistic Regression applies the sigmoid function to map outputs between 0 and 1, making it suitable for classification."
      ],
      "metadata": {
        "id": "whSYhTC-XwEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the mathematical equation of Logistic Regression?\n",
        "Logistic Regression predicts the probability P(Y=1‚à£X) that an instance belongs to the positive class. It is based on the logistic (sigmoid) function:\n",
        "P(Y=1‚à£X)= 1/\n",
        "1+e\n",
        "‚àí(w\n",
        "0\n",
        "‚Äã\n",
        " +w\n",
        "1\n",
        "‚Äã\n",
        " X\n",
        "1\n",
        "‚Äã\n",
        " +w\n",
        "2\n",
        "‚Äã\n",
        " X\n",
        "2\n",
        "‚Äã\n",
        " +...+w\n",
        "n\n",
        "‚Äã\n",
        " X\n",
        "n\n",
        "‚Äã\n",
        " )\n",
        "\n",
        "\n",
        "Here,\n",
        "\n",
        "w\n",
        "0\n",
        "‚Äã\n",
        "  is the intercept (bias),\n",
        "\n",
        "w\n",
        "1\n",
        "‚Äã\n",
        " ,w\n",
        "2\n",
        "‚Äã\n",
        " ,...,w\n",
        "n\n",
        "‚Äã\n",
        "  are the weights (coefficients) of the features,\n",
        "\n",
        "X\n",
        "1\n",
        "‚Äã\n",
        " ,X\n",
        "2\n",
        "‚Äã\n",
        " ,...,X\n",
        "n\n",
        "‚Äã\n",
        "  are the feature values,\n",
        "\n",
        "e is the Euler‚Äôs number (~2.718),\n",
        "\n",
        "The function outputs a probability between 0 and 1.\n",
        "\n",
        "The decision rule is:\n",
        "\n",
        "If P(Y=1‚à£X)‚â•0.5, classify as positive (1).\n",
        "\n",
        "Otherwise, classify as negative (0)."
      ],
      "metadata": {
        "id": "nzUhcLXCX64s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "The Sigmoid function is used because:\n",
        "\n",
        "It converts any real-valued input into a probability range (0 to 1).\n",
        "\n",
        "It helps interpret the output as a probability for binary classification.\n",
        "\n",
        "It is differentiable, making it useful for optimization using gradient descent."
      ],
      "metadata": {
        "id": "72qYpm7AX67p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the cost function used in Logistic Regression?\n",
        "\n",
        "Logistic Regression uses the Log Loss (Binary Cross-Entropy) Cost Function:\n",
        "\n",
        "ùêΩ\n",
        "(\n",
        "ùë§\n",
        ")\n",
        "=\n",
        "‚àí\n",
        "1/\n",
        "ùëö\n",
        "‚àë(i=1 to m)\n",
        "[\n",
        "ùë¶\n",
        "ùëñ\n",
        "log\n",
        "‚Å°\n",
        "(\n",
        "ùë¶\n",
        "^\n",
        "ùëñ\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "‚àí\n",
        "ùë¶\n",
        "ùëñ\n",
        ")\n",
        "log\n",
        "‚Å°\n",
        "(\n",
        "1\n",
        "‚àí\n",
        "ùë¶\n",
        "^\n",
        "ùëñ\n",
        ")\n",
        "]\n",
        "\n",
        "Where:\n",
        "h\n",
        "Œ∏\n",
        "‚Äã\n",
        " (x) is the predicted probability.\n",
        "\n",
        "ùë¶\n",
        "ùëñ\n",
        "  is the actual class label (0 or 1).\n",
        "\n",
        "m is the number of samples.\n"
      ],
      "metadata": {
        "id": "_A_CSsIXX6-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "Regularization prevents overfitting by adding a penalty term to the cost function:\n",
        "\n",
        "L1 (Lasso) Regularization: Adds absolute value of weights ‚à£Œ≤‚à£, leading to\n",
        "                           feature selection.\n",
        "\n",
        "L2 (Ridge) Regularization: Adds squared weights Œ≤^2, reducing large\n",
        "                           coefficients.\n",
        "                           \n",
        "It is needed to avoid overfitting and improve generalization.\n"
      ],
      "metadata": {
        "id": "CXy41OK4X7AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n",
        "Lasso (L1): Shrinks some coefficients to zero, effectively performing feature selection.\n",
        "\n",
        "Ridge (L2): Reduces all coefficients but does not make them zero.\n",
        "\n",
        "Elastic Net: A combination of L1 + L2, balancing both feature selection and weight shrinking."
      ],
      "metadata": {
        "id": "MKcroOf9X7Ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "Use Elastic Net when:\n",
        "\n",
        "There are highly correlated features (it handles them better than Lasso).\n",
        "\n",
        "The dataset has many irrelevant features (it selects features while preventing too much sparsity)."
      ],
      "metadata": {
        "id": "3PgVpkW0X7FG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the impact of the regularization parameter (Œª) in Logistic Regression?\n",
        "\n",
        "Higher Œª (stronger regularization) ‚Üí More shrinkage of coefficients, reducing overfitting.\n",
        "\n",
        "Lower Œª (weaker regularization) ‚Üí Allows more flexibility but may lead to overfitting.\n"
      ],
      "metadata": {
        "id": "M2f1mgePX7Hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What are the key assumptions of Logistic Regression?\n",
        "\n",
        "Linearity of independent variables with log-odds.\n",
        "\n",
        "No multicollinearity (high correlation between independent variables is undesirable).\n",
        "\n",
        "No extreme outliers in independent variables.\n",
        "\n",
        "Large enough sample size to ensure statistical reliability.\n"
      ],
      "metadata": {
        "id": "1srV6ckeX7LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "Decision Trees\n",
        "\n",
        "Random Forest\n",
        "\n",
        "Support Vector Machines (SVM)\n",
        "\n",
        "Na√Øve Bayes\n",
        "\n",
        "Neural Networks"
      ],
      "metadata": {
        "id": "7yxcNsSGmq85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What are Classification Evaluation Metrics?\n",
        "\n",
        "Accuracy ‚Äì Overall correctness of predictions.\n",
        "\n",
        "Precision ‚Äì How many predicted positives are actually positive.\n",
        "\n",
        "Recall (Sensitivity) ‚Äì How many actual positives were correctly predicted.\n",
        "\n",
        "F1-Score ‚Äì Harmonic mean of precision & recall.\n",
        "\n",
        "ROC-AUC Score ‚Äì Evaluates model discrimination between classes.\n"
      ],
      "metadata": {
        "id": "zK_UILIemq_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How does class imbalance affect Logistic Regression?\n",
        "\n",
        "Logistic Regression assumes equal class distribution, leading to biased predictions.\n",
        "\n",
        "Solutions:\n",
        "Use weighted loss functions (give more weight to minority class).\n",
        "Resampling techniques (oversampling the minority or undersampling the majority class).\n",
        "\n",
        "Use different algorithms like Random Forest or SMOTE for balancing."
      ],
      "metadata": {
        "id": "yrtsc6gmmrBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "It involves selecting the best hyperparameters, such as:\n",
        "\n",
        "Regularization strength (Œª)\n",
        "\n",
        "Choice of solver (e.g., 'liblinear', 'saga')\n",
        "\n",
        "Methods:\n",
        "\n",
        "Grid Search (exhaustive search over parameters).\n",
        "\n",
        "Random Search (randomly selects parameters for efficiency)."
      ],
      "metadata": {
        "id": "B7yBBX5dmrDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "liblinear ‚Äì Best for small datasets, works well with L1/L2 penalties.\n",
        "\n",
        "lbfgs ‚Äì Good for multi-class classification (default in Scikit-Learn).\n",
        "\n",
        "sag ‚Äì Good for large datasets.\n",
        "\n",
        "saga ‚Äì Supports L1/L2, works well for large-scale problems.\n"
      ],
      "metadata": {
        "id": "F-L7GmKumrGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "Two main approaches:\n",
        "\n",
        "One-vs-Rest (OvR): Trains one classifier per class vs. all others.\n",
        "\n",
        "Softmax (Multinomial Regression): Directly predicts probabilities for all classes using a generalization of the sigmoid function.\n"
      ],
      "metadata": {
        "id": "m2tf9ehwmrJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Simple and interpretable.\n",
        "\n",
        "Works well when features are linearly separable.\n",
        "\n",
        "Fast training and inference.\n",
        "\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Assumes linear decision boundaries.\n",
        "\n",
        "Sensitive to outliers.\n",
        "\n",
        "May not perform well with high-dimensional or complex data.\n"
      ],
      "metadata": {
        "id": "T5np4HgfnZwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What are some use cases of Logistic Regression?\n",
        "\n",
        "Medical Diagnosis (e.g., predicting heart disease).\n",
        "\n",
        "Spam Email Detection.\n",
        "\n",
        "Customer Churn Prediction.\n",
        "\n",
        "Credit Risk Assessment.\n"
      ],
      "metadata": {
        "id": "4jbUImtwnZzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        "Logistic Regression is used for binary classification (0 or 1).\n",
        "\n",
        "Softmax Regression is used for multi-class classification by predicting probabilities for multiple classes."
      ],
      "metadata": {
        "id": "dVmlv7zHnZ1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "\n",
        "Use OvR when classes are imbalanced or when training efficiency matters.\n",
        "\n",
        "Use Softmax when classes are balanced and interpretability is important.\n"
      ],
      "metadata": {
        "id": "kSZAt_lsnZ3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "Each coefficient\n",
        "Œ≤i\n",
        "‚Äã represents how a unit change in\n",
        "Xi\n",
        "  affects the log-odds of the positive class.\n",
        "\n",
        "The odds ratio can be calculated as:\n",
        "\n",
        "If e^(ùõΩi) > 1 ‚Üí Feature increases probability of positive class.\n",
        "\n",
        "If e^(ùõΩi) < 1 -> Feature decreases probability of positive class.\n"
      ],
      "metadata": {
        "id": "3GTjoZOVnZ51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRACTICAL QUESTIONS**"
      ],
      "metadata": {
        "id": "nvvAivwMnZ8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "#     Regression, and prints the model accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "data\n",
        "\n",
        "df =  pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = data.target\n",
        "df = df[df['target'] != 2]\n",
        "\n",
        "x = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.20, random_state = 1)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy is : \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA0nmu8Ssv9v",
        "outputId": "b02ae06a-949d-4ac4-9d0a-fd244754af28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is :  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
        "#    and print the model accuracy.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with L1 regularization (Lasso) is:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWKVqc0HuNVf",
        "outputId": "58a37f63-24ed-4485-b3a5-aa52618fd96d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with L1 regularization (Lasso) is: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "# LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(penalty='l2', max_iter=1000)\n",
        "\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with L2 regularization (Ridge) is:\", accuracy)\n",
        "\n",
        "coefficients = classifier.coef_\n",
        "print(\"Coefficients of the model:\")\n",
        "print(coefficients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmgMgGhvuNZG",
        "outputId": "32e27d07-353e-4a31-fa30-00ca596b639c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with L2 regularization (Ridge) is: 1.0\n",
            "Coefficients of the model:\n",
            "[[ 0.46100411 -0.78836575  2.18624929  0.92865666]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Elastic Net regularization is:\", accuracy)\n",
        "\n",
        "coefficients = classifier.coef_\n",
        "print(\"Coefficients of the model:\")\n",
        "print(coefficients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-MOY0Kiv28d",
        "outputId": "ea4eb1c7-438f-4b51-bcaa-5c7409cfd06f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Elastic Net regularization is: 1.0\n",
            "Coefficients of the model:\n",
            "[[ 0.         -0.9168213   2.49726757  0.5870102 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "# multi_class='ovr'\n",
        "\n",
        "classifier = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy for multiclass classification (OvR) is:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPzg9knkv2-n",
        "outputId": "0a92043c-ce07-4da7-9580-e3fa46b30bab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for multiclass classification (OvR) is: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.\"Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
        "#      Regression. Print the best parameters and accuracy.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Accuracy from GridSearchCV:\", best_accuracy)\n",
        "\n",
        "y_pred = grid_search.predict(x_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Parameters:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ4kWj2tv3A7",
        "outputId": "7173dc43-112a-4689-f771-4e1fd7d94226"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Best Accuracy from GridSearchCV: 1.0\n",
            "Test Accuracy with Best Parameters: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "#    average accuracy.\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "cv_scores = cross_val_score(classifier, x, y, cv=stratified_kfold, scoring='accuracy')\n",
        "\n",
        "average_accuracy = cv_scores.mean()\n",
        "print(\"Average Accuracy from Stratified K-Fold Cross-Validation:\", average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nW03jn1v3DS",
        "outputId": "bd89f336-2d7b-4ce3-dd6e-6344bb133e92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy from Stratified K-Fold Cross-Validation: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "# Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "from scipy.stats import uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': uniform(0.01, 100),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "random_search = RandomizedSearchCV(classifier, param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=1)\n",
        "random_search.fit(x_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "best_accuracy = random_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Accuracy from RandomizedSearchCV:\", best_accuracy)\n",
        "\n",
        "y_pred = random_search.predict(x_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Parameters:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rlCa8eVv3Fk",
        "outputId": "9b37ddab-e1f1-4e4b-e679-e6972dbe63f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 41.7122004702574, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy from RandomizedSearchCV: 1.0\n",
            "Test Accuracy with Best Parameters: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy for One-vs-One (OvO) Multiclass Logistic Regression is:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRm9QDcLv3It",
        "outputId": "a245322a-7e44-4735-b1ef-862ab1e129e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for One-vs-One (OvO) Multiclass Logistic Regression is: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "#      classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title(\"Confusion Matrix for Binary Classification\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "PtMLEkKAv3MI",
        "outputId": "fa83bf04-c5c4-4565-9e8a-bf6e5a6e3511"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "#     Recall, and F1-Score.\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)"
      ],
      "metadata": {
        "id": "nyjKFogKx8Ve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71275f65-8a4c-479d-96c8-1039d7005c9c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "#      improve model performance\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Class Weights:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxLdePPFx8Xd",
        "outputId": "d074bf23-72fd-4c98-f285-7de9680d8294"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Class Weights: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "# evaluate performance\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "df = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Age'] = imputer.fit_transform(df[['Age']])\n",
        "\n",
        "x = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n",
        "\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on Titanic Dataset:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC0_rcLHx8Zx",
        "outputId": "3be581c4-edcb-4665-83e1-8683fa5858aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Class Weights: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "#      model. Evaluate its accuracy and compare results with and without scaling.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "accuracy_without_scaling = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy without Feature Scaling:\", accuracy_without_scaling)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "classifier_scaled = LogisticRegression(max_iter=1000)\n",
        "classifier_scaled.fit(x_train_scaled, y_train)\n",
        "\n",
        "y_pred_scaled = classifier_scaled.predict(x_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "print(\"Accuracy with Feature Scaling:\", accuracy_with_scaling)\n",
        "\n",
        "if accuracy_with_scaling > accuracy_without_scaling:\n",
        "    print(\"Feature Scaling improved accuracy.\")\n",
        "elif accuracy_with_scaling < accuracy_without_scaling:\n",
        "    print(\"Feature Scaling reduced accuracy.\")\n",
        "else:\n",
        "    print(\"Feature Scaling did not change accuracy.\")"
      ],
      "metadata": {
        "id": "cZxab0llx8fN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be39d9e8-eff1-4a55-e2ad-87f6436876d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Feature Scaling: 1.0\n",
            "Accuracy with Feature Scaling: 1.0\n",
            "Feature Scaling did not change accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_pred_proba = classifier.predict_proba(x_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNoPTOCYN8Ok",
        "outputId": "120d0403-4101-4d22-84d6-cc9256f2e5db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17.  Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "from sklearn.metrics import accuracy_score\n",
        "classifier = LogisticRegression(C=0.5, max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Custom Learning Rate (C=0.5):\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHcYfjhSN8R1",
        "outputId": "8c5ae39f-1b1f-431a-bbe2-2c7206678cc5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Custom Learning Rate (C=0.5): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "coefficients = classifier.coef_[0]\n",
        "feature_importance = pd.DataFrame({'Feature': x.columns, 'Coefficient': coefficients})\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eeUA1MJN8VW",
        "outputId": "6075b303-f644-47be-9a57-ac5ad23d4fdc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            "             Feature  Coefficient\n",
            "0  sepal length (cm)     0.461004\n",
            "1   sepal width (cm)    -0.788366\n",
            "2  petal length (cm)     2.186249\n",
            "3   petal width (cm)     0.928657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen‚Äôs Kappa Score.\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen‚Äôs Kappa Score:\", kappa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Zcs_PHPtJF",
        "outputId": "454928a3-9c1c-4a20-eb1f-93a7ff9173ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen‚Äôs Kappa Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred_proba = classifier.predict_proba(x_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "TwJ1DsMNPtMg",
        "outputId": "25157f97-ca3b-47e9-d771-f21cbafa352c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    classifier = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {solver} solver: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9SRB76MPtud",
        "outputId": "18a9e9e3-482b-4d39-f53e-e93ef76687d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear solver: 1.0\n",
            "Accuracy with saga solver: 1.0\n",
            "Accuracy with lbfgs solver: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "# Correlation Coefficient (MCC).\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQW6shdsPt-n",
        "outputId": "5a049f0c-25e8-4e4b-e077-b0483aad9354"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "#      accuracy to see the impact of feature scaling.\n",
        "\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on Raw Data:\", accuracy_raw)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "classifier_scaled = LogisticRegression(max_iter=1000)\n",
        "classifier_scaled.fit(x_train_scaled, y_train)\n",
        "\n",
        "y_pred_scaled = classifier_scaled.predict(x_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(\"Accuracy on Standardized Data:\", accuracy_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4KsuD3pYbOE",
        "outputId": "2c50e1b7-da40-44cb-c560-aa1b7902d27b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Raw Data: 1.0\n",
            "Accuracy on Standardized Data: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
        "#      cross-validation.\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "best_C = grid_search.best_params_['C']\n",
        "print(\"Optimal C (Regularization Strength):\", best_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOVG10h8YbRZ",
        "outputId": "acdaf570-aae8-4fd2-c2f3-e06ccb876b67"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C (Regularization Strength): 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "# make predictions.\n",
        "import joblib\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "joblib.dump(classifier, 'logistic_regression_model.pkl')\n",
        "\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "y_pred = loaded_model.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Loaded Model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IltMiqtEYwLt",
        "outputId": "e459c70e-a66e-432b-89da-3fd1298d5e27"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Loaded Model: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLwgF0FzY4sy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}